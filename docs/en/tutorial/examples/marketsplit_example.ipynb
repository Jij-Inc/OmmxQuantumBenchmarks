{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e5097a",
   "metadata": {},
   "source": [
    "# Dataset Usage Example (using Marketsplit)\n",
    "\n",
    "This example demonstrates how to work with datasets in OMMX Quantum Benchmarks using Marketsplit as a representative case.\n",
    "\n",
    "**Important**: The patterns shown here apply to ALL datasets in the collection (Labs, Portfolio, Topology, etc.). Simply replace `Marketsplit` with any other dataset class name - the API is identical across all datasets.\n",
    "\n",
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d76b55",
   "metadata": {},
   "outputs": [],
   "source": "from ommx_quantum_benchmarks.qoblib import Marketsplit\n\n# Initialize the dataset\ndataset = Marketsplit()\n\nprint(f\"Dataset: {dataset.name}\")\nprint(f\"Description: {dataset.description}\")\nprint(f\"Available models: {dataset.model_names}\")\n\n# Check available instances\nfor model, instances in dataset.available_instances.items():\n    print(f\"{model}: {len(instances)} instances\")"
  },
  {
   "cell_type": "markdown",
   "id": "261b8bf9",
   "metadata": {},
   "source": [
    "Output:\n",
    "```\n",
    "Dataset: 01_marketsplit\n",
    "Available models: ['binary_linear', 'binary_unconstrained']\n",
    "binary_linear: 160 instances\n",
    "binary_unconstrained: 160 instances\n",
    "```\n",
    "\n",
    "## Working with Binary Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb40d1",
   "metadata": {},
   "outputs": [],
   "source": "# Load a specific instance\nmodel_name = \"binary_linear\"\ninstance_name = \"ms_03_050_002\"\n\ninstance, solution = dataset(model_name, instance_name)\n\nprint(f\"Loaded instance: {instance_name}\")\nprint(f\"Instance type: {type(instance)}\")\nprint(f\"Solution available: {solution is not None}\")\n\nif solution:\n    print(f\"Objective value: {solution.objective}\")\n    print(f\"Feasible: {solution.feasible}\")\n    print(f\"Number of variables: {len(solution.state.entries)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "8ced351c",
   "metadata": {},
   "source": [
    "## Solution Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a1393",
   "metadata": {},
   "outputs": [],
   "source": "if solution is not None:\n    # Evaluate the solution using the instance\n    evaluated = instance.evaluate(solution.state)\n    \n    print(\"Solution Verification:\")\n    print(f\"Original objective: {solution.objective}\")\n    print(f\"Evaluated objective: {evaluated.objective}\")\n    print(f\"Objectives match: {solution.objective == evaluated.objective}\")\n    \n    print(f\"Original feasibility: {solution.feasible}\")  \n    print(f\"Evaluated feasibility: {evaluated.feasible}\")\n    print(f\"Feasibility matches: {solution.feasible == evaluated.feasible}\")\n    \n    # Check state consistency\n    state_match = solution.state.entries == evaluated.state.entries\n    print(f\"States match: {state_match}\")"
  },
  {
   "cell_type": "markdown",
   "id": "9400acf4",
   "metadata": {},
   "source": [
    "## Analyzing Multiple Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1a2dd",
   "metadata": {},
   "outputs": [],
   "source": "# Analyze first 5 instances of each size category\ndef analyze_marketsplit_instances():\n    results = []\n    \n    # Group instances by size (extract size from name)\n    size_groups = {}\n    for instance_name in dataset.available_instances[\"binary_linear\"]:\n        # Extract size info from name like \"ms_03_050_002\"\n        parts = instance_name.split('_')\n        if len(parts) >= 3:\n            size_key = f\"{parts[1]}_{parts[2]}\"  # e.g., \"03_050\"\n            if size_key not in size_groups:\n                size_groups[size_key] = []\n            size_groups[size_key].append(instance_name)\n    \n    # Analyze one instance from each size group\n    for size_key, instances in list(size_groups.items())[:5]:\n        instance_name = instances[0]  # Take first instance of this size\n        \n        try:\n            instance, solution = dataset(\"binary_linear\", instance_name)\n            \n            if solution:\n                evaluated = instance.evaluate(solution.state)\n                results.append({\n                    'instance': instance_name,\n                    'size_category': size_key,\n                    'objective': solution.objective,\n                    'feasible': solution.feasible,\n                    'variables': len(solution.state.entries),\n                    'verification_passed': (\n                        solution.objective == evaluated.objective and\n                        solution.feasible == evaluated.feasible\n                    )\n                })\n                \n        except Exception as e:\n            print(f\"Error with {instance_name}: {e}\")\n    \n    return results\n\n# Run analysis\nresults = analyze_marketsplit_instances()\n\nprint(\"\\\\nAnalysis Results:\")\nprint(f\"{'Instance':<15} {'Size':<8} {'Variables':<10} {'Objective':<12} {'Feasible':<9} {'Verified':<9}\")\nprint(\"-\" * 70)\n\nfor r in results:\n    print(f\"{r['instance']:<15} {r['size_category']:<8} {r['variables']:<10} \"\n          f\"{r['objective']:<12.2f} {str(r['feasible']):<9} {str(r['verification_passed']):<9}\")"
  },
  {
   "cell_type": "markdown",
   "id": "6a04b514",
   "metadata": {},
   "source": [
    "## Performance Comparison: Binary Linear vs Unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2136cd8",
   "metadata": {},
   "outputs": [],
   "source": "import time\n\ndef compare_model_performance():\n    \\\"\\\"\\\"Compare loading performance between binary linear and unconstrained models.\\\"\\\"\\\"\n    test_instances = [\n        \"ms_03_050_002\", \"ms_04_050_001\", \"ms_05_050_001\"\n    ]\n    \n    results = {\n        \"binary_linear\": [],\n        \"binary_unconstrained\": []\n    }\n    \n    for model in [\"binary_linear\", \"binary_unconstrained\"]:\n        for instance_name in test_instances:\n            start_time = time.time()\n            try:\n                instance, solution = dataset(model, instance_name)\n                load_time = time.time() - start_time\n                results[model].append({\n                    'instance': instance_name,\n                    'load_time': load_time,\n                    'has_solution': solution is not None,\n                    'success': True\n                })\n            except Exception as e:\n                results[model].append({\n                    'instance': instance_name,\n                    'error': str(e),\n                    'success': False\n                })\n    \n    return results\n\n# Run comparison\nperf_results = compare_model_performance()\n\nfor model, results in perf_results.items():\n    print(f\"\\\\n{model.upper()} Model:\")\n    successful = [r for r in results if r.get('success', False)]\n    if successful:\n        avg_time = sum(r['load_time'] for r in successful) / len(successful)\n        print(f\"Average load time: {avg_time:.3f} seconds\")\n        print(f\"Success rate: {len(successful)}/{len(results)}\")\n    else:\n        print(\"No successful loads\")"
  },
  {
   "cell_type": "markdown",
   "id": "1a7ed7d7",
   "metadata": {},
   "source": [
    "## Integration with Quantum Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44454ba",
   "metadata": {},
   "outputs": [],
   "source": "# Example: Preparing Marketsplit data for QAOA\ndef prepare_for_qaoa(instance, solution):\n    \\\"\\\"\\\"\n    Prepare Marketsplit instance for QAOA algorithm.\n    This is a conceptual example - actual implementation depends on your quantum framework.\n    \\\"\\\"\\\"\n    \n    if solution is None:\n        print(\"No solution available for comparison\")\n        return None\n    \n    # Extract problem structure (conceptual)\n    problem_info = {\n        'num_variables': len(solution.state.entries),\n        'optimal_value': solution.objective,\n        'optimal_feasible': solution.feasible,\n        'variable_assignments': {\n            entry.id: entry.value for entry in solution.state.entries\n        }\n    }\n    \n    print(f\"Prepared QAOA problem with {problem_info['num_variables']} variables\")\n    print(f\"Target objective: {problem_info['optimal_value']}\")\n    \n    return problem_info\n\n# Usage\ninstance, solution = dataset(\"binary_unconstrained\", \"ms_03_050_002\")\nqaoa_problem = prepare_for_qaoa(instance, solution)"
  },
  {
   "cell_type": "markdown",
   "id": "ed954308",
   "metadata": {},
   "source": [
    "## Error Handling and Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021f986",
   "metadata": {},
   "outputs": [],
   "source": "def robust_marketsplit_loader(dataset, model_name, instance_pattern=None, max_instances=10):\n    \\\"\\\"\\\"Robustly load Marketsplit instances with comprehensive error handling.\\\"\\\"\\\"\n    \n    # Validate model name\n    if model_name not in dataset.model_names:\n        raise ValueError(f\"Invalid model '{model_name}'. Available: {dataset.model_names}\")\n    \n    available_instances = dataset.available_instances[model_name]\n    \n    # Filter instances if pattern provided\n    if instance_pattern:\n        available_instances = [\n            name for name in available_instances \n            if instance_pattern in name\n        ]\n    \n    # Limit number of instances\n    test_instances = available_instances[:max_instances]\n    \n    successful_loads = []\n    failed_loads = []\n    \n    for instance_name in test_instances:\n        try:\n            instance, solution = dataset(model_name, instance_name)\n            \n            # Verify solution if available\n            verification_ok = True\n            if solution:\n                try:\n                    evaluated = instance.evaluate(solution.state)\n                    verification_ok = (\n                        solution.objective == evaluated.objective and\n                        solution.feasible == evaluated.feasible\n                    )\n                except Exception as e:\n                    verification_ok = False\n                    print(f\"Verification failed for {instance_name}: {e}\")\n            \n            successful_loads.append({\n                'instance_name': instance_name,\n                'has_solution': solution is not None,\n                'verification_ok': verification_ok,\n                'objective': solution.objective if solution else None\n            })\n            \n        except Exception as e:\n            failed_loads.append({\n                'instance_name': instance_name,\n                'error': str(e)\n            })\n    \n    return successful_loads, failed_loads\n\n# Usage\nsuccessful, failed = robust_marketsplit_loader(\n    dataset, \n    \"binary_linear\", \n    instance_pattern=\"ms_03\",  # Only instances with \"ms_03\" in name\n    max_instances=5\n)\n\nprint(f\"Successfully loaded: {len(successful)} instances\")\nprint(f\"Failed to load: {len(failed)} instances\")\n\nif successful:\n    solutions_available = sum(1 for s in successful if s['has_solution'])\n    verified_solutions = sum(1 for s in successful if s['verification_ok'])\n    print(f\"Solutions available: {solutions_available}/{len(successful)}\")\n    print(f\"Solutions verified: {verified_solutions}/{solutions_available}\")"
  },
  {
   "cell_type": "markdown",
   "id": "07596482",
   "metadata": {},
   "source": [
    "This example demonstrates the key patterns for working with the Marketsplit dataset, including basic usage, solution verification, performance analysis, and robust error handling."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}